{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic Challenge (Beginner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: You do not need to understand the Python code or be able to write code to complete this tutorial and pass the Challenge.\n",
    "#### Remember to hit Shift+Enter in all the code cells to execute the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">A cell like this indicates a question you need to answer for this Challenge on the U4I platform. Please answer the question <b>before</b> continuing through the notebook.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[1. Introduction](#1)\\\n",
    "[2. Get familiar with the data](#2)\\\n",
    "[3. Prepare the data](#3)\\\n",
    "   [3a. Remove some features](#4)\\\n",
    "   [3b. Replace strings](#5)\\\n",
    "   [3c. Fill in missing data](#6)\\\n",
    "   [3d. Combine features](#7)\\\n",
    "[4. Visualize the data](#8)\\\n",
    "[5. Create a machine learning model](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=1></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered \"unsinkable\" RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren't enough lifeboats for everyone on board, resulting in the death of 1502 of the 2224 passengers and crew. While there was some element of luck involved in surviving, it seems some were more likely to survive than others.\n",
    "\n",
    "In this Challenge, you will use passenger data to build predictive model to answer the question: <b>Who was more likely to survive on the Titanic?</b>\n",
    "\n",
    "Source: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=2></a>\n",
    "## 2. Get familiar with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start exploring, we need to import the data set and some libraries that will help us with our calculations, visualizations, and machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# Import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import achine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 rows of data set\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our data set has a mixture of <b>categorical</b> and <b>numerical</b> features:\\\n",
    "`PassengerId`: Unique ID of the passenger\\\n",
    "`Survived`: Survived (1) or died (0)\\\n",
    "`Pclass`: Passenger's class (1st, 2nd, or 3rd)\\\n",
    "`Name`: Passenger's name\\\n",
    "`Sex`: Passenger's sex (male or female)\\\n",
    "`Age`: Passenger's age\\\n",
    "`SibSp`: Number of siblings/spouses aboard the Titanic\\\n",
    "`Parch`: Number of parents/children aboard the Titanic\\\n",
    "`Ticket`: Ticket number\\\n",
    "`Fare`: Fare paid for ticket\\\n",
    "`Cabin`: Cabin number\\\n",
    "`Embarked`: Where the passenger got on the ship (C - Cherbourg, S - Southampton, Q - Queenstown)\n",
    "\n",
    "From this we can already discern some information about passengers. For example, Braund Owen Harris was a 22-year-old man in 3rd class who did not survive.  \n",
    "\n",
    "Note: \"NaN\" is the abbreviation for \"Not a Number\". This is how Python represents missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q1 on the U4I platform</b>.\n",
    "    \n",
    "    Why could missing data (NaNs) be problematic for machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get an overview of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=3></a>\n",
    "## 3. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we work with any machine learning models, we need to ensure the data set is prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. The first step is to <b>remove some features</b> by answering the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which features contain blank, null, or empty values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing values in data set\n",
    "column_names = data.columns\n",
    "for column in column_names:\n",
    "    print(column + ': ' + str(data[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Cabin` has the most missing values (687), followed by `Age` (177), and then `Embarked` (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which features are mixed data types?\n",
    "`Ticket` is a mix of numeric and alphanumeric data types. `Cabin` is alphanumeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which features may contain errors or typos?\n",
    "`Name` might contain errors as are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we will remove the features `Ticket`, `Cabin`, and `Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features Ticket, Cabin, Name from data set\n",
    "data = data.drop(['Ticket', 'Cabin', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q2 on the U4I platform</b>.\n",
    "    \n",
    "    Why did we keep PassengerId in the data set? What must this column be used for in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q3 on the U4I platform</b>.\n",
    "    \n",
    "    If you could delete another varaible or column from the data set, which one would you delete and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Next, we need to <b>replace strings (text or letter sequences) with numbers</b> because the machine learning algorithms we will use cannot process words. We will replace female with 1, male with 0, S with 0, C with 1, and Q with 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace strings with numbers\n",
    "\n",
    "data['Sex'].replace('female', 1,inplace=True)\n",
    "data['Sex'].replace('male', 0 ,inplace=True)\n",
    "data['Embarked'].replace('S', 0,inplace=True)\n",
    "data['Embarked'].replace('C', 1,inplace=True)\n",
    "data['Embarked'].replace('Q', 2,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c. Data records are not always complete and this is also true for our data set. Missing data can interfere with machine learning algorithms so we need to <b>fill in the missing data</b>. One way to fill in missing values by using the available values in the data set (e.g., mean, median, mode), and approximating a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplement missing data in Age with median and Embarked with mode (most common value)\n",
    "\n",
    "data['Age'].fillna(data['Age'].dropna().median(), inplace=True)\n",
    "freq_port = data.Embarked.dropna().mode()[0]\n",
    "data['Embarked'].fillna(freq_port, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3d. Sometimes it can be useful to <b>combine features into new features</b> for visualizations and calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data categories for Age and Fare\n",
    "\n",
    "# Create 5 age groups\n",
    "\n",
    "data['AgeBand'] = pd.cut(data['Age'], 5)\n",
    "data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n",
    "data.loc[ data['Age'] <= 16, 'Age'] = 0\n",
    "data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n",
    "data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n",
    "data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n",
    "data.loc[ data['Age'] > 64, 'Age'] = 4\n",
    "data = data.drop(['AgeBand'], axis=1)\n",
    "\n",
    "# Create 4 fare groups\n",
    "\n",
    "data['Fare'].fillna(data['Fare'].dropna().median(), inplace=True)\n",
    "data['FareBand'] = pd.qcut(data['Fare'], 4)\n",
    "data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n",
    "data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n",
    "data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n",
    "data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare'] = 2\n",
    "data.loc[ data['Fare'] > 31, 'Fare'] = 3\n",
    "data['Fare'] = data['Fare'].astype(int)\n",
    "data = data.drop(['FareBand'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q4 on the U4I platform</b>.\n",
    "    \n",
    "    Describe how the variables Age and Fare were grouped?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q5 on the U4I platform (Bonus Question)</b>.\n",
    "    \n",
    "    The port designations S, C and Q were replaced by 0, 1 and 2. Linear models, such as perceptrons, assume that at a higher variable value the survival probability either increases or decreases. What is the problem with our approach (replacing port designations with 0, 1, and 2)? How can we avoid this problem? Think about how to do it better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 15 rows of new data set\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=4></a>\n",
    "## 4. Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing data is a great way to gain some insights and see some trends before applying any machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(data, col='Survived', row='Pclass', height=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "grid = sns.FacetGrid(data, row='Embarked', height=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "grid = sns.FacetGrid(data, row='Embarked', col='Survived', height=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=5></a>\n",
    "## 5. Create a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks need to be trained first. Insert why here! To do this, we will divide our data set into two: one for training the network, and one to test the network. Typically, 70% of the data is used as a training set and 30% as the test set. Insert why here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training set and test set\n",
    "train_df, test_df = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q6 on the U4I platform</b>.\n",
    "    \n",
    "    Why is it important to not use all the data as training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to separate the survival status, the outcome, from rest of the factors in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each data set (test and train) into two parts: X & Y\n",
    "\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(\"Survived\", axis=1)\n",
    "Y_test = test_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model. \n",
    "There are over 60 predictive modeling algorithms but not all apply to the problem we are trying to solve. Our problem is a classification and regression problem: we want to identify the relationship between passenger survival with other variables (e.g., sex, age, class). We are also perfoming a category of machine learning called supervised learning as we are training our model with a given data set. Given this, we have a few options for an algorithm: \n",
    "* LogisticRegression \n",
    "* LinearSVC \n",
    "* RandomForestClassifier \n",
    "* KNeighborsClassifier \n",
    "* GaussianNB \n",
    "* Perceptron \n",
    "* SGDClassifier \n",
    "* DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a specific algorithm we have specified a placeholder \"PLACEHOLDER()\" in the code cell below.\\\n",
    "Select one of the models and replace \"PLACEHOLDER\" with one of the options from the list above.\\\n",
    "For example, if you decide to use the first algorithm, the code will look like this:\\\n",
    "\n",
    "`# Apply machine learning algorithm LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply machine learning algorithm ________________\n",
    "\n",
    "model = PLACEHOLDER()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will see how well the chosen model predicts our data.\\\n",
    "The function scoretakes the values of the test data set (X_test), calculates with the model the corresponding values for the survival status, and compares them with the correct values (Y_test). The output value `acc_logof` is the probability that the model predicted survival status correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model and calculate accuracy\n",
    "\n",
    "acc_log = round(model.score(X_test, Y_test) * 100, 2)\n",
    "\n",
    "print(\"\\n  \\nThe accuracy of the model with respect to the test data is:\")\n",
    "print(acc_log)\n",
    "\n",
    "model_name=str(model)\n",
    "print(\"\\n \\nYou have used the following model for machine learning:\")\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q7 on the U4I platform</b>.\n",
    "    \n",
    "    Which machine learning model did you use? What is the accuracy of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q8 on the U4I platform (Bonus Question)</b>.\n",
    "    \n",
    "    Run the machine learning algorithm several rimes in a row (without changing the code). Why do you get a different accuracy each time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Pause! Answer <b>Q9 on the U4I platform (Bonus Question)</b>.\n",
    "    \n",
    "    Which model provides the highest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You have completed the Titanic Challenge (Beginner)! Remember to submit the exercise on the U4I platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources:\n",
    "https://www.kaggle.com/startupsci/titanic-data-science-solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
